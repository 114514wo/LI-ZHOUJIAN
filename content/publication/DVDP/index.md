---
title: "DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception"

# Authors
# Use short names or usernames consistent with your site; replace as needed
authors:
  - H. Min
  - admin
  - Y. Yang
  - J. Chen
  - S. Yuan

# Author notes (optional)
author_notes: []

# Publication date (use the actual arXiv submission date)
date: "2025-09-16T00:00:00Z"
doi: "10.48550/arXiv.2509.13024"

# Schedule page publish date (NOT publication's date).
publishDate: "2025-09-16T00:00:00Z"

# Publication type (CSL standard)
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "arXiv"
publication_short: "arXiv"

abstract: Automatic docking has long been a significant challenge in the field of mobile robotics. Compared to other automatic docking methods, visual docking methods offer higher precision and lower deployment costs, making them an efficient and promising choice for this task. However, visual docking methods impose strict requirements on the robot's initial position at the start of the docking process. To overcome the limitations of current vision-based methods, we propose an innovative end-to-end visual docking method named DVDP (direct visual docking policy). This approach requires only a binocular RGB-D camera installed on the mobile robot to directly output the robot's docking path, achieving end-to-end automatic docking. Furthermore, we have collected a large-scale dataset of mobile robot visual automatic docking dataset through a combination of virtual and real environments using the Unity 3D platform and actual mobile robot setups. We developed a series of evaluation metrics to quantify the performance of the end-to-end visual docking method. Extensive experiments, including benchmarks against leading perception backbones adapted into our framework, demonstrate that our method achieves superior performance. Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy, with our model generating smooth, feasible docking trajectories that meet physical constraints and reach the target pose.

# Summary (optional)
summary: End-to-end visual docking policy (DVDP) using RGB-D for mobile robots; state-of-the-art results and real-world deployment.

tags:
  - Robotics
  - Visual Docking
  - RGB-D Perception
  - End-to-End Policy

# Display this page in the Featured widget?
featured: true

# Disable social sharing
share: false

# Links
url_pdf: "DVDP.pdf"
url_source: "https://arxiv.org/abs/2509.13024"
url_code: ""
url_dataset: ""
url_poster: ""
url_project: ""
url_slides: ""
url_video: ""

# Featured image (expects `featured.jpg/png` in this folder)
image:
  caption: "DVDP"
  focal_point: ""
  preview_only: false

# Associated Projects (optional)
projects: []

# Slides (optional)
slides: ""
---

## Publication Details

**DOI:** 10.48550/arXiv.2509.13024  
**Preprint:** https://arxiv.org/abs/2509.13024  
**PDF:** DVDP.pdf

## Abstract

Automatic docking has long been a significant challenge in the field of mobile robotics. Compared to other automatic docking methods, visual docking methods offer higher precision and lower deployment costs, making them an efficient and promising choice for this task. However, visual docking methods impose strict requirements on the robot's initial position at the start of the docking process. To overcome the limitations of current vision-based methods, we propose an innovative end-to-end visual docking method named DVDP (direct visual docking policy). This approach requires only a binocular RGB-D camera installed on the mobile robot to directly output the robot's docking path, achieving end-to-end automatic docking. Furthermore, we have collected a large-scale dataset of mobile robot visual automatic docking dataset through a combination of virtual and real environments using the Unity 3D platform and actual mobile robot setups. We developed a series of evaluation metrics to quantify the performance of the end-to-end visual docking method. Extensive experiments, including benchmarks against leading perception backbones adapted into our framework, demonstrate that our method achieves superior performance. Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy, with our model generating smooth, feasible docking trajectories that meet physical constraints and reach the target pose.

## Key Contributions

- End-to-end visual docking policy using only a binocular RGB-D camera
- Large-scale dataset collected across simulation and real-world platforms
- New evaluation metrics tailored for visual docking performance
- Strong results vs. leading perception backbones within our framework
- Real-world deployment on SCOUT Mini with smooth, feasible trajectories

{{% callout note %}}
Click the _Cite_ button above to import publication metadata into your reference management software.
{{% /callout %}}

